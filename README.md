# batch_processing_wikimedia
Creation d'un data lake avec HDFS des historiques de pages sur Wikipedia et analyse des meilleurs contributeurs en batch avec Spark
